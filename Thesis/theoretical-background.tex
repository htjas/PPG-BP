In the Theoretical Background section, the essential medical and computational foundations are explored, providing a comprehensive reference for understanding the methodologies employed in this study.
This section offers insights into the physiological principles of BP monitoring~\ref{subsec:med_background}, alongside the computational frameworks utilized for predictive modeling~\ref{subsec:computing_background}.

\subsection{Medical Background}
\label{subsec:med_background}

\subsubsection{Blood Pressure}
\label{subsubsec:bp}

% general BP
BP is a physiological measure of the force exerted by circulating blood against the walls of the arteries~\cite{WhatBloodPressure2019}.
It is highly dependent on blood flow, which refers to the movement of blood through a vessel, tissue, or organ.
Blood circulation begins with the contraction of the heart's ventricles.
This action generates a type of hydrostatic pressure, which is the force exerted by a fluid due to gravitational pull, usually against the walls of the space that it is bound by.

BP is a type of hydrostatic pressure, representing the force exerted by blood on the walls of blood vessels or the heart's chambers.
While it can be assessed in various body regions, the term \enquote{blood pressure} without specific qualifiers commonly refers to systemic arterial BP\@.
This denotes the pressure of blood within the arteries of the systemic circulation.
In clinical settings, this pressure is measured in millimeters of mercury (mmHg) and is typically acquired using the brachial artery in the arm~\cite{betts20BloodFlow2022}.

% measuring significance
Measuring BP is crucial for assessing cardiovascular health and identifying potential risks.
It allows for the early detection of conditions like hypertension and hypotension, enabling timely interventions to prevent serious cardiovascular events~\cite{naylorArterialCathetersEarly2020}.
BP serves as a key indicator of the risk for heart attacks, strokes, and heart failure, guiding preventive measures and treatment strategies~\cite{ettehadBloodPressureLowering2016}.

\vspace{0.2cm}
\textit{Various Types of Measurement}
\vspace{0.2cm}

% cuff BP measuring
One of the most common BP measurement methods is one using a sphygmomanometer (see manual and automatic sphygmomanometers devices in Figure~\ref{fig:sphygmomanometers}), also known as \ac{NIBP}, is typically recorded as numeric values at specific time intervals.
The process involves inflating the cuff to temporarily stop blood flow and then gradually releasing the pressure to detect the sounds associated with the flow of blood through the brachial artery.
Manually, the measurement entails one individual conducting the procedure on another, typically involving a healthcare professional administering the assessment to a patient.
Conversely, automatic measurement allows the patient to independently measure their BP without external assistance.
Both approaches yield comparable measurements of the same nature.
The two primary values obtained are systolic pressure (maximum pressure during heartbeats) and diastolic pressure (minimum pressure between heartbeats).
During the process of cuff inflation and deflation, each heartbeat generates characteristic sounds (Korotkoff sounds) that are detected by a stethoscope placed over the brachial artery.
Systolic pressure is recorded when the first tapping sounds are heard, and diastolic pressure is recorded when the sounds disappear or change character.
This beat-to-beat approach provides information about individual fluctuations in BP~\cite{betts20BloodFlow2022}.

\begin{figure}[b]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=0.75\textwidth]{images/abp/sphyg}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=0.75\textwidth]{images/abp/auto_sphyg}
    \end{subfigure}
    \caption{Standard (left) and Automatic (right) Sphygmomanometers}
    \label{fig:sphygmomanometers}
\end{figure}

Although measuring BP with a cuff using a sphygmomanometer is widely adopted as a common and convenient method, it is not without its constraints.
Studies, such as those by Leung et al.\ and Sebo et al.\ , have highlighted the inability of home BP monitoring devices to consistently and accurately detect hypertension~\cite{leungHypertensionCanada20162016, seboBloodPressureMeasurements2014}.
Furthermore, a significant limitation lies in its inability to provide continuous and consistent monitoring, necessitating patients to actively remember and engage in the effort to measure their BP\@.
This intermittent approach using a cuff provides valuable insights into systolic and diastolic pressures at specific time intervals, but it may not capture the nuanced changes that occur between measurements.
To address the need for continuous monitoring, other methods, such as arterial catheterization, are employed.

% arterial BP
Arterial catheterization (illustrated in Figure~\ref{fig:catheter}) is commonly employed in critical patient care, serving dual purposes: continuous BP monitoring and obtaining frequent blood gas measurements.
Typically conducted at bedside, the procedure utilizes percutaneous methods like the Seldinger technique to cannulate arteries~\cite{clarkArterialCatheterization1992}.
The resulting \ac{ABP} is a dynamic parameter that can change with each heartbeat, and it is typically represented as a waveform rather than a single numeric value.
The ABP waveform consists of two main components: \ac{SBP} and \ac{DBP}.
Such continuous monitoring of ABP is usually done in clinical settings, using an arterial line connected to a pressure transducer.
The resulting waveform is displayed on a monitor in real-time.
However, for ease of interpretation and documentation, numeric values are commonly extracted from the waveform at specific time intervals~\cite{hillImputationContinuousArterial2021}.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{images/abp/catheter}
    \caption{Arterial Catheterization and Stationary BP Monitoring~\cite{contributorEssentialCriticalCare2021}}
    \label{fig:catheter}
\end{figure}

In situations where high temporal resolution is crucial, ABP can be recorded beat-to-beat, providing a value for each heartbeat.
This is particularly important in situations where rapid changes in BP need to be closely monitored, such as during certain medical procedures or in critically ill patients~\cite{lehmanMethodsBloodPressure2013}.

For routine monitoring and documentation, numeric values are often averaged over a specific time interval, such as every 1, 5, or 15 minutes.
This averaged value may be reported as the \ac{MAP}, which is a weighted average of the systolic and diastolic pressures over a cardiac cycle~\cite{demersPhysiologyMeanArterial2024}
Some monitoring systems may also provide systolic and diastolic BP readings at regular intervals.

Alternative approaches for measuring BP have emerged over the past years.
Volume clamping~\cite{kimBallistocardiogramBasedApproachCuffless2018} and tonometry~\cite{imholzFifteenYearsExperience1998} are some of the other methods.
These non-invasive techniques offer continuous monitoring of BP values.
Volume clamping, which involves the use of a small finger cuff and a PPG sensor, is one method for continuous BP measurement.
Tonometry, on the other hand, is a cuffless approach that utilizes a manometer-tipped probe pressed directly on an artery.
The volume clamping approach allows for instantaneous and prolonged BP measurement.
However, it is associated with high costs and still necessitates the use of a cuff, which can be inconvenient and uncomfortable.
Conversely, the tonometry method is sensitive to movement of the arm and probe, making it challenging to maintain accuracy in practical applications.
Additionally, constant calibration with a cuff BP device is required~\cite{peterReviewMethodsNoninvasive2014}.

\vspace{0.2cm}

In conclusion, BP serves as a critical physiological measure, representing the force exerted by blood on the walls of blood vessels.
The conventional method of measuring BP with a cuff and sphygmomanometer provides valuable insights into SBP and DBP but is limited by its intermittent nature.
To address the need for continuous monitoring, arterial catheterization is commonly employed in critical care, offering real-time data through a dynamic waveform.
Alternative non-invasive approaches like volume clamping and tonometry aim to provide continuous BP monitoring, but they come with their own challenges and considerations.
As technology advances, these methods contribute to a comprehensive understanding of BP dynamics, facilitating improved patient care and risk assessment.

\subsubsection{Photoplethysmography}
\label{subsubsec:ppg}

% meaning and basic information
PPG is an optical measurement technique designed to identify changes in blood volume within the microvascular bed of tissue~\cite{challonerPhotoelectricPlethysmographMeasurement1974}.
Its clinical application is extensive, as the technology is integrated into commercially available medical devices, including pulse oximeters, vascular diagnostics, and digital beat-to-beat BP measurement systems.
The fundamental structure of PPG technology is straightforward, requiring only a few opto-electronic components: a light source for tissue illumination, usually a \ac{LED} and a \ac{PD} to gauge slight variations in light intensity correlated with changes in perfusion in the catchment volume.

% history and origins
\vspace{0.2cm}
\textit{History}
\vspace{0.2cm}

One of the first mentioned instances on the use of PPG were recorded in 1936 by Molitor and Kniazuk~\cite{molitorNewBloodlessMethod1936}.
They outlined comparable devices employed for tracking alterations in blood volume in the rabbit ear under conditions of venous occlusion and the administration of vasoactive drugs.
A pioneer who played a key role in developing the PPG method was Alrick Hertzman~\cite{hertzmanPhotoelectricPlethysmographyFingers1937}.
In his 1937 publication, Hertzman introduced the term \enquote{Photoelectric Plethysmograph} etymologically meaning:
photo - \enquote{light}, plethora - \enquote{exess of body fluid, blood}, graph - \enquote{something written}.
He detailed the application of a reflection mode system to assess alterations in blood volume within the fingers, particularly during the Valsalva maneuver~\cite{srivastavValsalvaManeuver2024}, exercise, and exposure to cold.
This contribution not only demonstrated the versatility of the technique but also underscored its potential clinical relevance.

Hertzman and Spealman~\cite{hertzmanPhotoelectricPlethysmographyFingers1937} outlined two crucial features of the PPG pulse waveform.
They categorized the pulse appearance into two phases: the anacrotic phase representing the ascending edge of the pulse, and the catacrotic phase representing the descending edge of the pulse.
The initial phase primarily corresponds to systole, while the subsequent phase relates to diastole and wave reflections from the periphery.
In individuals with healthy compliant arteries, a dicrotic notch is commonly observed during the catacrotic phase.

In the late 1970s, there arose a renewed interest in the PPG technology, driven by the demand for compact, dependable, cost-effective, and user-friendly noninvasive cardiovascular assessment techniques~\cite{yoshiyaSpectrophotometricMonitoringArterial1980}.
The progress in opto-electronics and clinical instrumentation has played a significant role in advancing PPG technology.
Semiconductor advancements, particularly in LEDs, PDs, and phototransistors, have brought about substantial improvements in the size, sensitivity, reliability, and reproducibility of PPG probe design.
A significant leap in the clinical application of PPG-based technology occurred with the introduction of the pulse oximeter~\cite{aoyagiPulseOximetryIts2002}.
This device revolutionized non-invasive monitoring of patients' arterial oxygen saturation, marking a major advancement in the field.

Other emerging technologies encompass PPG imaging technology, telemedicine, and remote monitoring.
In 2005, Wieringa et al.\ detailed a contactless multiple-wavelength PPG imaging system designed primarily for remotely imaging the distribution of arterial SpO2 within tissue~\cite{wieringaContactlessMultipleWavelength2005b}.
The system captures movies of two-dimensional matrix spatially resolved PPG signals at different wavelengths during respiratory changes.
PPG was found to have substantial potential in telemedicine, particularly for remote/home health monitoring of patients.
Miniaturization, user-friendliness, and robustness stand as pivotal design criteria for such systems.
This is exemplified by finger ring-based PPG sensors for monitoring beat-to-beat pulsations (\cite{rheeArtifactresistantPowerefficientDesign2001}, ~\cite{zhengRingtypeDeviceNoninvasive2003}).

Most PPG devices these days either use the transmissive or reflective operating modes (illustrated in Figure~\ref{fig:reflection}).
Currently, the prevalent method is the transmissive mode, chosen for its notable accuracy and stability~\cite{leeReflectancePulseOximetry2016}.
However, there is a growing interest in reflective-mode PPG due to its elimination of the need for a thin measurement site.
This method proves versatile, applicable to various sites such as the feet, forehead, chest, and wrists.
Especially when the wrist serves as the designated measurement site, PPG sensors can be conveniently employed in the form of a band or watch.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{images/ppg/reflection}
    \caption{PPG Transmission (a) and Reflection (b) operating modes \cite{mohanSpotMeasurementHeart2016}}
    \label{fig:reflection}
\end{figure}

% how does it work
\vspace{0.2cm}
\textit{Working Principle}
\vspace{0.2cm}

The PPG signal consists of pulsate (AC) and superimposed (DC) components (see Figure~\ref{fig:acdc}).
The AC component originates from variations in blood volume associated with heartbeats,
while the DC component is influenced by factors such as respiration, sympathetic nervous system activity, and temperature regulation~\cite{allenPhotoplethysmographyItsApplication2007a}.
The AC component specifically illustrates changes in blood volume during phasic cardiac activity, representing both the systolic and diastolic phases.
The systolic phase, also known as the \enquote{rise time} initiates with a valley and concludes at the pulse wave systolic peak.
The pulse wave concludes with another valley at the end of the diastolic phase~\cite{weisslerSystolicTimeIntervals1968}.
In most PPG waveform analytic studies including this one, the AC component in the form of a waveform signal is used.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.5]{images/ppg/ac+dc}
    \caption{AC and DC components of the PPG signal \cite{mohanSpotMeasurementHeart2016}}
    \label{fig:acdc}
\end{figure}

% main and potential use cases
\vspace{0.2cm}
\textit{Use Cases}
\vspace{0.2cm}

PPG finds diverse applications in clinical settings, covering physiological monitoring (such as blood oxygen saturation and heart rate), vascular assessment (including arterial disease, aging and tissue viability), and autonomic function evaluations (such as thermoregulation, heart rate and other assessments of cardiovascular variability)~\cite{allenPhotoplethysmographyItsApplication2007a}.
Furthermore, the popularity of PPG technology as an alternative for monitoring heart rate has risen recently, primarily attributed to its ease of use, user-friendly wearing comfort, and cost-effectiveness~\cite{sviridovaHumanPhotoplethysmogramNew2015}.
Nowadays, almost every wearable devices uses the PPG technology to track the user's heart rate and other extractable vital parameters~\cite{castanedaReviewWearablePhotoplethysmography2018}.
PPG sensors in mobile and wearable devices typically feature red, green, or both light-emitting diodes.
Most devices incorporate a green-light PPG sensor for continuous heart rate monitoring during daily activities.
Some devices also include red-light PPG sensors, which are effective for measuring heart rate when a person is stationary, providing insights into hydration, muscle saturation, and total hemoglobin.
While red-light PPG can penetrate tissue layers more deeply using near-infrared spectroscopy, it is susceptible to disturbance from ambient light.
In contrast, green light, being less absorbed by the skin, minimizes the impact of ambient light noise on the heart rate signal.
As a result, wearable devices commonly utilize green light rather than red-light PPG~\cite{ponnadaTechnologicalConsiderationsSensorassisted2019}.
Different types of devices implement the PPG technology.
It can be found in pulse oximeters, smartphones, smartwatches and other wearable devices (examples in Figure~\ref{fig:ppg-devices}).

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.35]{images/ppg/ppg-devices}
    \caption{AC and DC components of the PPG signal \cite{zanelliPotentialAIBased2023}}
    \label{fig:ppg-devices}
\end{figure}

% Conclusion parahraph
\vspace{0.2cm}

In conclusion, the PPG is an optical sensor, consisting of an LED paired with a PD, hence it is simple, cost-effective and can be readily integrated into a wearable device.
The PPG waveform can be obtained using two modes, reflectance and transmission.
This waveform represents the volume of blood within the blood vessels.
Traditionally employed in healthcare for heart rate and blood oxygen saturation measurements, particularly with pulse oximeters, the PPG plays a pivotal role~\cite{allenPhotoplethysmographyItsApplication2007a}.

% outlook to SP and ML
Additionally, peripheral volumetric changes exhibit correlation with BP~\cite{langewoutersPressurediameterRelationshipsSegments1986}.
Utilizing characteristic PPG features, ML functions can estimate SBP and DBP\@.
However, establishing a simple, clear, and continuous relationship between these features and BP remains elusive.
This method relies heavily on signal pre-processing, feature extraction, and the application of ML algorithms for BP estimation based on these features.

\subsubsection{MIMIC Databases}
\label{subsubsec:mimic}

Patient records and documentation are crucial for maintaining a comprehensive overview of medical history, aiding in accurate diagnosis, treatment planning, and ensuring continuity of care.
They also serve as legal documents, providing evidence of the care provided and facilitating communication among healthcare professionals.
Collecting digital data during routine clinical practice has become widespread across hospitals.
Over time, a pattern has emerged in the collection and storage of patient data for subsequent utilization in future research endeavors.

% History and Origin
\vspace{0.2cm}
\textit{Origin}
\vspace{0.2cm}

In 1996, two researchers at the Massachusetts Institute of Technology, George B. Moody and Roger G. Mark, introduced the \ac{MIMIC} \ac{DB}.
The DB was derived from patient monitors in the medical, surgical, and cardiac ICUs of Boston’s Beth Israel Hospital~\cite{moodyDatabaseSupportDevelopment1996}.
The first instance of the DB included 100 patient records, each typically containing between 24 and 48 hours of continuous recorded data.
The second version of the DB (MIMIC-II) was introduced in 2011 boasting a notably larger sample size and a wider scope of information sourced entirely from diverse digital information systems~\cite{saeedMultiparameterIntelligentMonitoring2011}.
MIMIC-III~\cite{johnsonMIMICIIIFreelyAccessible2016} was finalized in 2016, marking a significant expansion from MIMIC-II, with data available from over 40,000 patients.
The fourth and latest MIMIC DB was publicly released in 2023 spanning a decade of admissions from 2008 to 2019.
MIMIC-IV was announced to enhance the realm of publicly accessible critical care datasets, by integrating precise digital sources like the electronic medicine administration record and featuring a modular structure enabling seamless integration with external departments and diverse data modalities~\cite{johnsonMIMICIVFreelyAccessible2023}.
The diagram in Figure~\ref{fig:mimic_workflow} depicts the component interaction for data and information delivery to the publicly available DB\@.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.75]{images/mimic/mimic_workflow}
    \captionsetup{format=plain, justification=raggedright}
    \caption{Workflow between Beth Israel Deaconess Medical Center (BIDMC), Protected Health Information (PHI) DB and the MIT hosted MIMIC DB server~\cite{charltonMIMICWFDBTutorials2022}}
    \label{fig:mimic_workflow}
\end{figure}

% Structure of MIMIC DB
\vspace{0.4cm}
\textit{Structure}
\vspace{0.2cm}

Both the MIMIC-III and MIMIC-IV DBs are cited and employed in this investigation, exhibiting comparable structures (depicted in Figure~\ref{fig:mimic_structure}), encompassing diverse data categories.
However, the primary emphasis of this inquiry lies in the Waveform Section of the DB (highlighted by a red rectangle in Figure~\ref{fig:mimic_structure}).
The waveform DB comprises individual records, each representing a patient's ICU stay and stored in a distinct subdirectory.
These records lack specific date or time data to ensure patient anonymity, relying instead on elapsed time from the record's start.
They are supplemented by surrogate date and time information for cross-referencing with other DB modules.
Waveforms denote regularly sampled, high-resolution measurements stored in a signal specific numerical format.
To optimize storage and processing, these waveforms are segmented into intervals, maintaining continuous sampling within each segment despite potential signal unavailability throughout a patient's ICU stay.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.3]{images/mimic/mimic_structure}
    \caption{General Structure of the MIMIC-III DB~\cite{johnsonMIMICIIIFreelyAccessible2016}}
    \label{fig:mimic_structure}
\end{figure}

The Waveform data from both the MIMIC-III and MIMIC-IV DBs is publicly available on the Physionet internet website~\cite{moodyMIMICIIIWaveformDatabase2017, moodyMIMICIVWaveformDatabase}.
In both DBs recorded waveforms typically encompass one or more \ac{ECG} signals, often feature continuous ABP waveforms and fingertip PPG signals.
Numeric data typically includes heart and respiration rates, SpO2, SBP, DBP and MAP, among other metrics when accessible.
Recording durations also vary, with most lasting a few days, although some are shorter and others might even extend over several weeks.
Both projects consist of two types of data: waveform data, comprising high-resolution, regularly sampled time series obtained directly from measuring devices, and numeric data, including digitally derived values or irregularly sampled data (like NIBP).

% Differences MIMIC3 and MIMIC4
\vspace{1cm}
\textit{Differences and Similarities between MIMIC-III and MIMIC-IV}
\vspace{0.2cm}

In MIMIC-III, waveforms were collected in a largely automated manner from selected adult and neonatal ICUs, resulting in a random sample of patients.
The data archiving process was not continuous, and the recorded waveforms and numerics varied based on ICU staff choices.
The individual patient consent was waived due to de-identification.
On the other hand, MIMIC-IV stored data from ICUs, where bedside monitors were linked to a local area network, allowing continuous monitoring and data transfer to a proprietary relational DB\.
Data was stored for several weeks before being retrieved and archived daily.
The de-identification process for MIMIC-IV followed the same method as MIMIC-III, removing or replacing protected health information with non-identifying information.

Both the MIMIC-III and MIMIC-IV DBs encompass waveform and numeric datasets sourced from ICUs.
While both datasets feature detailed waveform records and numerical values, their storage and acquisition methods differ.
MIMIC-III organizes its records within a directory structure with segmented waveform data, while MIMIC-IV adopts the \ac{WFDB} format for waveforms and compressed \ac{CSV} files for numerics.
However, MIMIC-IV incorporates enhancements like automated record partitioning and optimized storage formats to enhance data management efficiency.

% Conclusion parahraph
\vspace{0.2cm}

Clinical Research DBs such as MIMIC play a pivotal role in facilitating global access to critical patient data, thereby supporting scientific endeavors across various medical domains.
By ensuring the anonymity and de-identification of patient information, these DBs uphold stringent standards of data privacy and ethics, thereby avoiding any infringement upon patient rights or privacy regulations.
Such DBs serve as invaluable resources for conducting comprehensive studies spanning diverse medical disciplines, including but not limited to the detection and treatment of various cancers, cardiovascular diseases, and even neonatal care in stationary settings.
Their expansive datasets offer researchers an extensive pool of information to draw insights from, ultimately advancing the overall understanding and management of complex medical conditions.

\subsection{Computing Background}
\label{subsec:computing_background}

\subsubsection{Signal Processing}
\label{subsubsec:signal_processing}

PPG-based BP estimation has emerged as a promising non-invasive approach, utilizing waveform observations from signals like PPG, recorded from different anatomical sites, or their combination with ECG signals.
This section delves into the diverse methodologies and algorithms utilized for processing PPG signals to derive meaningful insights into BP dynamics.

% Different types of filters for processing the PPG signal
\vspace{0.2cm}
\textit{Signal Pre-Processing}
\vspace{0.2cm}

Data preprocessing stands as an essential procedure in signal processing, serving as a pivotal precursor to precise and substantive analysis.
Tailored to the specific dataset and analytical objectives, this process involves addressing irregular or absent data through techniques like resampling and interpolation,
as well as employing diverse filtering methods for data smoothing~\cite{DataScientistGuide}.
As indicated in the forthcoming methodology sections (see~\ref{subsec:data-fetching}), the consistency of signals utilized in this study is guaranteed through alternative methods, thus rendering resampling and interpolation unnecessary.
On the other hand, filtering is a significant component of this investigation, which is elaborated in the following section.

% Explain the need of signal filtering, in terms of processing and data interpretation.

Signal filtering is essential in processing physiological data like PPG signals to ensure accurate and reliable interpretation.
It serves to remove unwanted noise and artifacts from the signal, which could otherwise obscure the underlying physiological information~\cite{liangOptimalFilterShort2018}.
Artifacts are undesired signals that enter the signal processing system, causing distortion or errors in the output~\cite{SignalProcessingArtifacts}.
Without proper filtering, the raw signal may contain various unwanted components that can hinder data interpretation and analysis.

% elaborate on which signal components or artifacts might interfere.

PPG signals can be susceptible to various signal components or artifacts that may interfere with the accurate representation of physiological changes.
These disturbances include Baseline Wander, characterized by slow variations in the signal due to shifts in posture or patient movement.
Motion Artifacts, on the other hand, introduce high-frequency noise stemming from the movement of the patient.
Muscle Artifacts, a type of electromyographic (recorded electrical activity produced by skeletal muscles) interference, arise from muscle contractions and can distort the PPG signal.
Additionally, Ambient Light Interference poses a challenge, as external light sources can affect the readings captured by the PPG sensor.
Lastly, Electrical Interference, originating from electronic devices or power sources, presents another source of noise that can obscure the desired physiological information within the PPG signal~\cite{maityPPGMotionModelbasedDetection2022}.

%  explain what kind of filters are needed to eliminate those disturbances.

To mitigate these disturbances and isolate the desired physiological information, specific filtering techniques are needed.
High-pass filters are utilized to eliminate low-frequency disruptions such as baseline drift, allowing only the higher-frequency components to pass through.
Conversely, low-pass filters are employed to eliminate high-frequency disturbances such as muscle noise or electrical interferences.
Bandpass filters prove to be ideal for isolating the specific frequency range of interest while effectively filtering out any undesired frequencies~\cite{rajivLowPassHigh2022}.

% name actual filters which actually would be able of removing such disturbances and appropriately preparing the signal.

Three filters that have shown to effectively remove these disturbances and prepare the signal for analysis include the Butterworth, Chebyshev and Saviztky-Golay filers~\cite{kanwalComparativeAnalysisPhotoplethysmography2023}.
The Butterworth Filter is often chosen for its smooth frequency response, effectively removing both low and high-frequency noise to offer versatility in signal processing~\cite{storrButterworthFilterDesign2013}.
In contrast, the Chebyshev Filter stands out for its capability to achieve a sharper roll-off in the stopband, enabling precise control over the transition width and the passband ripple~\cite{ChebyshevFilterOverview}.
On the other hand, the Savitzky-Golay Filter possesses a unique trait—it performs both signal smoothing and differentiation, making it an ideal choice for noise removal while retaining the essential features of the underlying signal~\cite{gallagherSavitzkyGolaySmoothingDifferentiation}.

% Butterworth
An investigation into various signal pre-processing techniques necessitates an examination of these different types of filters.
Belonging to the Infinite Impulse Response (IIR) category, Butterworth filters offer efficiency in processing low-frequency signals and exhibit rapid computational capabilities, as demonstrated by Chatterjee et al.\ in their PPG-based heart rate analysis~\cite{chatterjeePPGBasedHeart2018}.
The filter order directly correlates with the number of energy storage components present in the analogous analog circuit, such as inductors and capacitors.
The transfer function of a Butterworth filter is represented by the following formula, where \texttt{n} is the filter order and \texttt{z} is the complex variable used in Z-transform analysis:

\Large
\begin{center}
    \begin{math}
        H(z) = \frac{1}{[1 + (z^{-1})^{n}]^{1/2}}
    \end{math}
\end{center}
\normalsize

% SavGol
Another noteworthy filter type is the Savitzky-Golay filter, introduced by Savitzky and Golay~\cite{savitzkySmoothingDifferentiationData1964}.
Falling under the Finite Impulse Response (FIR) category, this filter effectively smooths data while removing unwanted frequencies.
Its inherent stability ensures a finite output for any finite input.
Additionally, the linear phase property guarantees the absence of frequency-dependent time shifts.
The Savitzky-Golay filter doesn't have a single transfer function like the Butterworth filter, because it operates based on a polynomial fitting approach.
Instead of a standard convolutional operation, it fits a simple mathematical curve to nearby data points in the signal.
This process smooths out the signal by finding the average trend in each neighborhood of points.
The filter then uses these curves to adjust the values in the signal, making it less noisy.
The degree of the curve and the size of the neighborhood affect how much smoothing the filter applies.
The relationship can be expressed by the following formula:

\begin{center}
    \Large
    \begin{math}
        y[n] = \sum_{i=-\frac{M}{2}}^{\frac{M}{2}} W_i \cdot x_{n+i}
    \end{math}

    \normalsize
    \begin{tabular}{ll}
        $M$       & : Window size (odd number greater than or equal to $N+1$) \\
        $N$       & : Polynomial degree                                       \\
        $W_i$     & : Filter coefficients (length $M$)                        \\
        $x_{n+i}$ & : Signal data point                                       \\
        $y[n]$    & : Smoothed data point
    \end{tabular}
\end{center}

% Chebyshev
The last examined filter is the Chebyshev, which is known for its steep drop-off in frequencies it blocks, which means it can separate wanted and unwanted frequencies more sharply than some other filters.
This advantage comes at the expense of some ripple in the allowed frequencies, but it's still a great choice for tasks that require precise separation of different frequencies.
It exhibits a higher degree of complexity compared to the Butterworth filter due to its dependency on parameter settings, which directly influence its operational characteristics.
Unlike the Savitzky-Golay filter that uses pre-calculated curves, the Chebyshev filter's settings decide how much ripple it allows and how steeply it cuts off frequencies.
The general form of the Chebyshev filter transfer function depends on whether it's Type I (with ripple in both allowed and blocked frequencies) or Type II (ripple only in the blocked frequencies).
The corresponding functions are presented by the following formulas:

\begin{multicols}{2}
    \begin{center}
        Chebyshev I \\
        \vspace{0.2cm}
        \large
        \begin{math}
            H(z) = K \prod_{n=1}^{N} \left[ 1 - \frac{\varepsilon}{(T_n(z))^2} \right]
        \end{math}
        \normalsize
        \begin{tabular}{ll}
            $K$           & : Gain factor                 \\
            $\varepsilon$ & : Normalized passband         \\           & \;\, ripple level (dB)                \\
            $N$      & : Filter order \\
            $T_n(z)$      & : Chebyshev polynomial of the \\      & \;\, first kind, evaluated at $z$ \\
        \end{tabular}
    \end{center}
    \columnbreak
    \begin{center}
        Chebyshev II \\
        \vspace{0.2cm}
        \large
        \begin{math}
            H(z) = K \cdot \frac{z^N - 1}{\prod_{n=1}^{N} \left[ z^2 - 2 \zeta z \cos(\omega_n) + 1 \right]}
        \end{math}
        \normalsize
        \begin{tabular}{ll}
            $K$        & : Gain factor                        \\
            $N$        & : Filter order                       \\
            $\zeta$    & : Normalized stopband damping factor \\
            $\omega_n$ & : Normalized cutoff frequency        \\
        \end{tabular}
    \end{center}
\end{multicols}

% Optimal finding
In their 2018 study, Liang et al.\ investigated nine different digital signal filters to identify the optimal approach for short PPG signals (2.1s)~\cite{liangOptimalFilterShort2018}.
Some of the filters included the Butterworth, Elliptical, Chebyshev Type I and II, Median Filter etc.
Their performance-based ranking revealed the Chebyshev II filter as the most effective in enhancing PPG signal quality, with the optimal order at 4th.

To summarize, the preprocessing of physiological signals, crucial for accurate BP estimation, involves a variety of signal filtering methods.
Techniques like Chebyshev, Butterworth, and Savitzky-Golay filters play pivotal roles in enhancing signal quality.
These preprocessing steps, facilitated by advancements in computational technology, pave the way for more refined analysis and interpretation of PPG pulse waves.
The practical implementation of the aforementioned filters is documented in the methodology subsection~\ref{subsubsec:filtering}.

\vspace{0.6cm}
\textit{PPG Signal Processing Methods}
\vspace{0.2cm}

Following an extensive examination of signal filtering methodologies, the subsequent section elaborates on the specific signal processing techniques employed in previous studies.

% PTT
Early research has documented an inverse relationship BP and \ac{PTT}~\cite{mukkamalaUbiquitousBloodPressure2015}.
Extensive investigation over past decades has focused on the PTT-based approach, revealing growing support for its potential in offering non-invasive BP measurements without the need for cuffs.
PTT refers to the delay in time for the pressure waveform to traverse between two arterial locations (see Figure~\ref{fig:ptt}).
It can be calculated by measuring the time gap between the proximal and distal waveforms, which represent the arterial pulse.

\begin{figure}[h]
    \centering
    \begin{minipage}{0.42\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/sp/ptt}
        \captionsetup{format=plain, justification=centering, font=small}
        \caption{Calculation of PTT from ECG, PPG and first PPG derivative waveforms~\cite{luiNovelCalibrationProcedure2018}}
        \label{fig:ptt}
    \end{minipage}\hfill
    \begin{minipage}{0.42\textwidth}
        \centering
        \includegraphics[width=\linewidth]{images/sp/pat}
        \captionsetup{format=plain, justification=centering, font=small}
        \caption{Calculation of PAT from ECG and PPG waveforms~\cite{dhillonPulseArrivalTime2019}}
        \label{fig:pat}
    \end{minipage}
\end{figure}

% PAT
\ac{PAT} represents another widely employed technique~\cite{sharmaCuffLessContinuousBlood2017}.
It is defined as the time that takes the pulse wave to travel from the heart to a peripheral site e.g.\ finger, toe, etc.
It denotes the temporal discrepancy between the R-peak of the ECG signal and the peak of the PPG signal, measured within the same cardiac cycle (see Figure~\ref{fig:pat}).
Both PTT and PAT require simultaneous measurement at two different sites on the body, hence two measurement sensors (ECG and PPG) are needed for recording the signals in order to estimate these parameters.

% PWV
\ac{PWV} is another alternative method for estimating BP~\cite{mccombieAdaptiveBloodPressure2006}.
PWV determines the speed of the pulse wave by utilizing two PPG sensors positioned along the same arterial branch, separated by a known distance (see Figure~\ref{fig:pww}), portrayed by the following formula
\begin{math}
    PWW = \frac{D}{PTT}
\end{math}
where D is the distance between two known body parts.

\begin{figure}
    \begin{minipage}[c]{0.5\textwidth}
        \includegraphics[width=0.90\textwidth]{images/sp/pww}
    \end{minipage}\hfill
    \begin{minipage}[c]{0.5\textwidth}
        \captionsetup{format=plain, justification=centering, font=small}
        \caption{Calculation of PWW from two PPG signals at different body parts~\cite{urbanUnderstandingArterialBiomechanics2023}}
        \label{fig:pww}
    \end{minipage}
\end{figure}

\vspace{-1cm}
% summarize PTT,PAT,PWV
Estimating BP through PTT, PAT, or PWV parameters involves mathematical models, but implementing these models faces challenges, and none of these techniques has become a reliable clinical tool for BP measurement.
Challenges include the need for synchronized sensors, varying sampling rates, and reliance on complex arterial wave propagation models, making continuous BP measurement inconvenient and requiring constant calibration.
Despite being calibrated on a per-person basis, these models provide only short-term BP estimations and are unreliable for beat-to-beat BP measurements.
Therefore, they were not explicitly included in this study, however, they offer valuable insights into PPG signal processing.

% PWA
\ac{PWA} conversely, offers a multifaceted solution to the previously mentioned issues and was implemented in this research, as documented in sections~\ref{subsubsec:fidp} and~\ref{subsubsec:features}.
It serves as an umbrella term encompassing signal processing and feature extraction of certain PPG waveform characteristics.
PWA offers a novel method for cuffless, continuous, and calibration-free BP measurement by extracting temporal features from the PPG waveform, which demonstrate a strong correlation with individual BP levels~\cite{elgendiAnalysisFingertipPhotoplethysmogram2012}.
Utilizing only one PPG sensor, PWA presents several advantages over previous methods, including simplicity, affordability, straightforward signal acquisition, and a resemblance between BP pulse waveform and PPG blood volume pulse (example in Figure~\ref{fig:pwa}).
This data-driven approach to BP estimation provides optical BP measurement with promising potential for practical applications.
Advancements in computational technology and data analysis software have simplified the preprocessing and analysis of physiological signals.
Techniques such as filtering and feature extraction are commonly utilized in the analysis of PPG pulse waves, often integrated into ML and \ac{DNN} models for BP estimation~\cite{mahardikatPPGSignalsBasedBloodPressure2023}.

\begin{figure}[h]
    \includegraphics[width=0.9\textwidth]{images/sp/pwa}
    \caption{Example of a PWA used to extract features from the PPG waveform~\cite{bikiaLeveragingPotentialMachine2021}}
    \label{fig:pwa}
\end{figure}

A study conducted by Takazawa et al.\ investigated the utilization of the second derivative of the fingertip PPG waveform within clinical contexts~\cite{takazawaAssessmentVasoactiveAgents1998a}.
The research analysed changes in patients' pressure, wave ratios, age-related variations, and correlations with health conditions.
Collectively, the results indicate the potential value of the second derivative in appraising the impacts of specific medications and assessing vascular health and aging, offering potential avenues in arteriosclerotic disease screening.
Subsequent research has demonstrated the effective application of the second derivative of the PPG waveform in identifying the dicrotic notch within a single pulse wave (see Figure~\ref{fig:dic_notch}), a critical landmark in PWA\@.

\begin{figure}[b]
    \centering
    \includegraphics[width=0.6\textwidth]{images/sp/dic_notch}
    \caption{Dicrotic Notch Approximation from the Second Derivate of the PPG~\cite{djeldjliImagingPhotoplethysmographySignal2019}}
    \label{fig:dic_notch}
\end{figure}

In 2022, Charlton et al.\ conducted a collaborative study to investigate the hemodynamic characteristics of PPG waveforms for the purpose of vascular age assessment~\cite{charltonAssessingHemodynamicsPhotoplethysmogram2022}.
A key outcome of their work was the identification of a comprehensive set of features, termed \enquote{fiducial points}, which could be extracted from the PPG waveform to achieve accurate vascular age estimation.

The term \enquote{fiducial} originates from the Latin \textit{fiducialis}, meaning \enquote{reliable}.
In the context of signal processing, it refers to reference points employed for precise measurements.
In the early cases, it has been used for accurate determination of PTT between the R-wave of the ECG and a designated point in a finger PPG pulse, as demonstrated by Zhang et al.~\cite{zhangEffectLocalCold2005}.
In the study by Charlton et al., these points were repurposed to delineate diverse landmarks (identified as Row A in Figure~\ref{fig:fiducials}) on the pulse wave, serving as references for extracting both temporal and amplitude-based features.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.8]{images/sp/fiducials}
    \caption{A - Fiducial Point Identification; B - Feature Calculation~\cite{charltonAssessingHemodynamicsPhotoplethysmogram2022}}
    \label{fig:fiducials}
\end{figure}

Building upon the identified fiducial points, Charlton et al.\ employed various techniques to extract meaningful values from a single PPG signal (Row B in Figure~\ref{fig:fiducials}) that contribute to vascular age assessment.
This section provides a summary of the implemented methods and corresponding example values (presented in brackets):
\begin{enumerate}
    \setlength{\itemsep}{-0.2\parsep}
    \item Pulse Wave Features (crest time: time from \texttt{onset} to \texttt{sys})
    \item First Derivative Features (minimum rise time: amplitude of pulse wave divided by amplitude of \texttt{ms})
    \item Second Derivative Features (aging index: defined as amplitude values of \mbox{\texttt{(b-c-d-e)/a)}}
    \item Combination of Features (minimum rise time: \texttt{[1/x0(ms)]·[x(sys) - x(onset)]})
    \item Frequency Domain Analysis (\ac{FFT}) analysis: Use of FFT to derive amplitude and phase information from the PPG signal)
    \item Features From Multiple Beats (pulse rate variability parameters)
\end{enumerate}

\vspace{0.2cm}
This section explored diverse signal processing techniques.
As mentioned previously, traditional methods relying on physiological parameters (PAT, PTT, PWV) face limitations.
Signal processing approaches like PWA, filtering, and feature extraction are often integrated with ML models and provide a higher BP detection accuracy.
These approaches show promising results for cuffless, continuous BP estimation using PPG signals, paving the way for practical NIBP monitoring solutions.
All practical implementations utilized in this study, based on these theoretical and past-research findings, are documented in methods section~\ref{subsec:sp_methods}

\subsubsection{Machine Learning}
\label{subsubsec:machine_learning}
% Basix
ML forms the cornerstone of predictive modeling in various fields, including healthcare.
At its core, ML involves the development of algorithms and statistical models that allow computers to learn from and make predictions or decisions based on data~\cite{WhatMachineLearning}.
Supervised learning, a common ML approach, involves training a model on labeled data, where the algorithm learns the relationship between input features (like PPG signals) and the target output (such as BP).
Unsupervised learning, on the other hand, deals with finding hidden patterns or structures in unlabeled data, which can be beneficial for feature extraction~\cite{deluaSupervisedVsUnsupervised2021}.
In the context of this thesis, various supervised learning techniques are utilized to analyse PPG waveform features and to predict BP values.
These algorithms are trained on datasets from ICU patients to create regression models capable of estimating BP from PPG data.

Building upon the foundation laid by traditional signal processing techniques, as elaborated in section~\ref{subsubsec:signal_processing}, ML emerges as a transformative force in the pursuit of accurate and non-intrusive BP estimation using PPG signals.
This section delves into the diverse range of ML methods currently employed, thoroughly exploring their individual approaches and their collective potential to improve cuffless BP monitoring.

\newpage

% ML Techniques
\textit{Machine Learning BP Prediction Approaches}
\vspace{0.2cm}

BP estimation using ML techniques is data driven, unlike the traditional PTT/PAT only models.
Several studies attempted to fit regression models, such as multilinear regression, \ac{SVM} and random forest, for estimating BP using PTT/PAT based approach with some degree of success, but the results did not always satisfy the international standards.

As early as 2003, Teng and Zhang~\cite{tengContinuousNoninvasiveEstimation2003} were among the pioneers in exploring non-invasive methods for estimating BP without the need for traditional cuff-based techniques.
They explored the relationship between four PPG features and BP using a \ac{LR} model.
While diastolic time exhibited the strongest correlation with both SBP and DBP, the overall results suggested limitations in LR for accurate BP estimation.

Recognizing these limitations, Suzuki and Oguri (2009) introduced AdaBoost, a classifier for SBP estimation~\cite{suzukiCufflessBloodPressure2009}.
This methodology segmented SBP values using a threshold before employing a nonlinear ML model, showcasing the need for more complex techniques.

Seeking a different approach, Ruiz-Rodriguez et al.\ (2013) utilized a \ac{DBN} \ac{RBM} for simultaneous prediction of SBP, DBP, and MAP~\cite{ruiz-rodriguezInnovativeContinuousNoninvasive2013}.
An example DBN and RBM with custom input and output sizes is illustrated in Figure~\ref{fig:rbm}.
However, the study yielded highly variable results, raising concerns about its reliability.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{images/ml/RBM}
    \captionsetup{format=plain, justification=raggedright}
    \caption{\small A DBN (a) combines multiple layers of RBMs (b) to form a generative model capable of learning hierarchical representations of the data~\cite{ouIntegratingCellularAutomata2019}}
    \label{fig:rbm}
\end{figure}

Shifting focus to feature extraction, Kurylyak et al.\ (2013) extracted 21 features from the PPG waveform and used a feedforward \ac{NN} (example in Figure~\ref{fig:ffnn}) for SBP and DBP estimation~\cite{kurylyakNeuralNetworkbasedMethod2013}.
Their promising results demonstrated the potential of NN-based approaches.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{images/ml/ffnn}
    \captionsetup{format=plain, justification=raggedright}
    \caption{\small Feed Forward NNs have connections between the nodes that do not form cycles, allowing data to move in only one direction, from the input nodes through the hidden nodes to the output nodes, with each connection having an associated weight~\cite{FeedforwardNeuralNetworks}.}
    \label{fig:ffnn}
\end{figure}

Xing and Sun (2016) ventured into the frequency domain, applying FFT to select features followed by a feedforward NN for BP estimation~\cite{xingOpticalBloodPressure2016}.
While initial results were encouraging, the authors recognized the need for broader feature space exploration.

Building upon Kurylyak et al.'s work, Liu et al.\ (2017) incorporated 14 second derivative features and employed an SVM for BP estimation, highlighting the value of diverse feature extraction techniques~\cite{liuIntegratedNavigationTethered2017}.

Marking a significant shift, Su et al.\ (2018) explored a four-layer \ac{LSTM} model with residual connections, demonstrating the promise of recurrent NNs~\cite{suLongtermBloodPressure2018}.
The working principle of an LSTM is demonstrated in Figure~\ref{fig:lstm}.

A 2019 study by Tanveer and Hasan introduced a hierarchical Artificial NN-LSTM model for BP estimation, comprising two levels: the lower level employed artificial NNs to extract morphological features from ECG and PPG waveforms, while the upper level utilized LSTM layers to address temporal variations in these features~\cite{tanveerCufflessBloodPressure2019}.
They also found, that DBP is strongly associated with SBP and can enhance its estimation, suggesting simultaneous modeling using a single architecture for both.

Focusing on long term estimation, El-Hajj and Kyriacou (2021) proposed leveraging advanced deep learning techniques like Bidirectional-LSTM and Bidirectional \ac{GRU} with attention mechanisms for BP estimation~\cite{el-hajjDeepLearningModels2021}.

Recognizing the need for real-world applicability, Joung et al.\ (2023) evaluated a learning-driven cuffless BP estimation system under challenging conditions with calibration~\cite{joungContinuousCufflessBlood2023}.
Their 1D convolutional NN highlighted the importance of addressing various real-world scenarios.

These studies illustrate the evolution of ML techniques for cuffless BP estimation, paving the way for further advancements.
From exploring linear relationships to harnessing the power of deep learning, researchers continue to refine and develop novel approaches.
While challenges remain, these pioneering efforts demonstrate the immense potential of ML in improving non-invasive BP monitoring, and future research holds the promise for even more accurate and robust solutions.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{images/ml/lstm}
    \captionsetup{format=plain, justification=raggedright}
    \caption{\small Bidirectional LSTM is a type of recurrent NN architecture that processes sequential data in both forward and backward directions. This allows the model to capture dependencies from past and future contexts simultaneously, enhancing its ability to understand and predict patterns in sequential data~\cite{anishnamaUnderstandingBidirectionalLSTM2023}.}
    \label{fig:lstm}
\end{figure}

\vspace{0.2cm}

To conclude, the relationship between PPG characteristics and BP was not found to consistently follow a linear trend.
Conventional linear models frequently struggle to effectively capture the complex relationship between BP and PPG when analysed across various demographic datasets.
Traditional ML algorithms like SVMs and Random Forest tend to achieve higher accuracy rates in this context.
To estimate BP accurately using these techniques, distinct models are typically constructed for SBP and DBP\@.
However, recent evidence suggests that a unified architecture capable of simultaneously modeling SBP, DBP, and even MAP is both feasible and advantageous.
Various advanced NN models demonstrate superior efficiency in integrating such architectures and leveraging extensive datasets with heightened precision relative to conventional ML approaches.
The chosen ML model, incorporated within this study, are detailed in the methods section~\ref{subsec:ml_methods}, with their outcomes presented in section~\ref{subsec:machine_learning}.